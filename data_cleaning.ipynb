{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuntul17/project-cycling/blob/main/data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB3D6WHjI3Hj",
        "outputId": "748eeea0-ff98-41f3-89c7-1b627b8f15b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fitparse\n",
            "  Downloading fitparse-1.2.0.tar.gz (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fitparse\n",
            "  Building wheel for fitparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fitparse: filename=fitparse-1.2.0-py3-none-any.whl size=68212 sha256=67e7699daa65ddae1eb52bbac488af6821d42ecfae2dc2c0107a92fa71b6f73d\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/67/7b/77a2f8ba348bafbbad6262a80bc51be27b2f9fccbaefc74671\n",
            "Successfully built fitparse\n",
            "Installing collected packages: fitparse\n",
            "Successfully installed fitparse-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fitparse\n",
        "import fitparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ezFueZL7I_82"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#import numpy as np\n",
        "#from pylab import *\n",
        "#import seaborn as sns\n",
        "#import folium\n",
        "import os, shutil\n",
        "import zipfile\n",
        "import gzip\n",
        "#import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbisKP4VKYRg"
      },
      "outputs": [],
      "source": [
        "folder =\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/raw_data/StravaData\"\n",
        "os.chdir(folder)\n",
        "df0 = pd.DataFrame()\n",
        "# Open the ZIP file\n",
        "for n,f in enumerate(os.listdir()):\n",
        "  if \".gpx\" in f:\n",
        "    continue\n",
        "  tablecontent = {}\n",
        "  with gzip.open(f, 'rb') as gz_file:\n",
        "    # Read the content of the GZIP file\n",
        "    F = gz_file.read()\n",
        "  ff = fitparse.FitFile(F)\n",
        "  units = []\n",
        "  for r in ff.get_messages(\"record\"): #r is record\n",
        "    for d in r:\n",
        "      # d is data field\n",
        "      dataname = d.name\n",
        "      datavalue = d.value\n",
        "      unit = d.units\n",
        "      if dataname in tablecontent:\n",
        "        tablecontent[dataname].append(datavalue)\n",
        "      else:\n",
        "        tablecontent[dataname] = [datavalue]\n",
        "        units.append(unit)\n",
        "  dum = pd.DataFrame.from_dict(tablecontent, orient='index',).transpose()\n",
        "  dum[\"id\"] = n\n",
        "  df0 = pd.concat([df0, dum], ignore_index=True)\n",
        "df0.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/raw_rides.csv\",index=False)\n",
        "#save the units\n",
        "U = [{\"Feature\": feature, \"Units\": unit}\n",
        "     for feature, unit in zip(tablecontent.keys(), units)]\n",
        "\n",
        "# Create a DataFrame from the list of dictionaries\n",
        "unitdf = pd.DataFrame(U)\n",
        "unitdf.to_excel(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/units.xlsx\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5ohfwgsMB5s"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/raw_rides.csv\") #just to save some time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to convert to semicircles to coordinates\n",
        "#Since all the rides are from North-East semisphere I won't check the signs.\n",
        "def loc_converter(semi_lat,semi_lon):\n",
        "  lat = (semi_lat / 2**31) * 180\n",
        "  lon = (semi_lon/2**31)*180\n",
        "  return lat, lon"
      ],
      "metadata": {
        "id": "LXMsMfLcMbr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#do not convert altitude\n",
        "#do not convert cadence\n",
        "df[\"distance\"] = df[\"distance\"]/1000 # meters to kilometers\n",
        "#do not convert heart_rate\n",
        "new_location = loc_converter(df[\"position_lat\"],df[\"position_long\"])\n",
        "df[\"position_lat\"] = new_location[0]\n",
        "df[\"position_long\"] = new_location[1]\n",
        "df[\"speed\"] = df[\"speed\"]* 3.6 # m/s to km/h\n",
        "df.drop([\"enhanced_altitude\",\"enhanced_speed\",\"power\",\"fractional_cadence\",\"unknown_66\",\"unknown_61\",\"unknown_108\"],axis=1,inplace= True)\n"
      ],
      "metadata": {
        "id": "fk7QnUHBMf0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing = pd.DataFrame()\n",
        "for i in df[\"id\"].unique():\n",
        "  subset = df[df[\"id\"]==i][df.columns[:-1]]\n",
        "  miss_rat = (subset.isna().mean()*100).round(3).to_dict()\n",
        "  dum1 = pd.DataFrame.from_dict(miss_rat,orient='index').transpose()\n",
        "  dum1[\"id\"] = i\n",
        "  dum1[\"time\"] = (subset[\"timestamp\"].iloc[0])[:10] #.astype(int)\n",
        "  missing = pd.concat([dum1,missing],ignore_index=True)\n",
        "missing = missing.iloc[::-1].reset_index(drop=True)\n",
        "#Now if any feature missing more than 15% of the each ride, I will those rides as `unusable` and other will be labelled as `usable`.\n",
        "threshold = 15\n",
        "missing['Usage'] = missing[missing.columns[:8]].apply(lambda row: 1 if all(row <= threshold) else 0, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "mFtSsAWM-EMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usage_mapping = missing.set_index('id')['Usage'].to_dict()\n",
        "df[\"Usage\"] = df[\"id\"].map(usage_mapping)\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/convertedrides.csv\",index=False)\n",
        "missing.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycyling data outputs/missing_values.csv\",index=False)"
      ],
      "metadata": {
        "id": "1DSvBxaXB4Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing[missing[\"Usage\"]==1]"
      ],
      "metadata": {
        "id": "1WjiQj-kIUyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/convertedrides.csv\")"
      ],
      "metadata": {
        "id": "nZU2qQa_XHKM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the summed data to clean.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/raw_data/activities.csv\")"
      ],
      "metadata": {
        "id": "fVgXh29ZP7Sn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"Activity ID\",'Activity Name','Commute', 'Activity Private Note', 'Activity Gear','Max Grade', 'Average Grade','Max Temperature', 'Average Temperature',\n",
        "       'Average Positive Grade', 'Average Negative Grade','Max Heart Rate.1',\n",
        "       'Filename', 'Athlete Weight', 'Bike Weight', 'Elapsed Time.1','Max Watts', 'Average Watts',\"Weighted Average Power\", \"Power Count\", \"Prefer Perceived Exertion\",\n",
        "       'Perceived Relative Effort','Activity Description', 'Commute.1', 'Total Weight Lifted',\n",
        "       'From Upload', 'Grade Adjusted Distance', 'Weather Observation Time',\n",
        "       'Weather Condition', 'Weather Temperature', 'Apparent Temperature','Distance.1',\n",
        "       'Dewpoint', 'Humidity', 'Weather Pressure', 'Wind Speed', 'Wind Gust',\n",
        "       'Wind Bearing', 'Precipitation Intensity', 'Sunrise Time',\n",
        "       'Sunset Time', 'Moon Phase', 'Bike', 'Gear','Max Grade', 'Average Grade',\n",
        "       'Average Positive Grade', 'Average Negative Grade','Elevation Low',\n",
        "       'Elevation High',\n",
        "       'Precipitation Probability', 'Precipitation Type', 'Cloud Cover',\n",
        "       'Weather Visibility', 'UV Index', 'Weather Ozone',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.jump_count\">Jump Count</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.total_grit\">Total Grit</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.avg_flow\">Avg Flow</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.flagged\">Flagged</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.avg_elapsed_speed\">Avg Elapsed Speed</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.dirt_distance\">Dirt Distance</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.newly_explored_distance\">Newly Explored Distance</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.newly_explored_dirt_distance\">Newly Explored Dirt Distance</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.sport_type\">Sport Type</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.total_steps\">Total Steps</span>',\n",
        "       'Media','Relative Effort.1', 'Total Work', 'Number of Runs', 'Uphill Time',\n",
        "       'Downhill Time', 'Other Time', 'Perceived Exertion',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.type\">Type</span>',\n",
        "       '<span class=\"translation_missing\" title=\"translation missing: en-US.lib.export.portability_exporter.activities.horton_values.start_time\">Start Time</span>'],inplace = True,axis = 1)\n",
        "df"
      ],
      "metadata": {
        "id": "pjv6064xQDh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"Activity Date\",\"Activity Type\",\"Distance\",'Elevation Gain','Elevation Loss',\n",
        "              'Elapsed Time','Moving Time','Average Speed','Max Speed','Average Cadence','Max Cadence',\n",
        "              'Average Heart Rate','Max Heart Rate','Relative Effort','Calories']]\n",
        "df = df[df[\"Activity Type\"]=='Ride'] #drop the runs\n",
        "df['Activity Date']=pd.to_datetime(df['Activity Date'], format='%b %d, %Y, %I:%M:%S %p')\n"
      ],
      "metadata": {
        "id": "0-tzcNt7ROk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(df, df0[['id', 'Usage','timestamp']], left_on='Activity Date', right_on='timestamp', how='left')\n",
        "\n",
        "# Drop the redundant timestamp column\n",
        "df = merged_df.drop(columns=['timestamp'])\n"
      ],
      "metadata": {
        "id": "c778KG5-P8ry"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/cleanNsummed.csv\",index=False)"
      ],
      "metadata": {
        "id": "hILk25S6b8R3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQnE6oW9cPPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19wy2J4h98uxKU6UxVeB9oQCMwVgZrNQR",
      "authorship_tag": "ABX9TyONsojTZlLL/P1HHPagSaTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
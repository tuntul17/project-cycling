# -*- coding: utf-8 -*-
"""cycling_adventure.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19wy2J4h98uxKU6UxVeB9oQCMwVgZrNQR
"""

!pip install fitparse
import fitparse

import pandas as pd
import numpy as np
from pylab import *
import seaborn as sns
import folium
import os, shutil
import zipfile
import gzip
import torch

"""The first goal is to create a heatmap of my rides and plot them on a map.
* Step 1: Read .fit files and save them as csv as it takes time to read initially.
* Step 2: Save the units for convertion. then convert to useful units.
*
"""

folder ="/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/raw_data/StravaData"
os.chdir(folder)
df0 = pd.DataFrame()
# Open the ZIP file
for n,f in enumerate(os.listdir()):
  if ".gpx" in f:
    continue
  tablecontent = {}
  with gzip.open(f, 'rb') as gz_file:
    # Read the content of the GZIP file
    F = gz_file.read()
  ff = fitparse.FitFile(F)
  units = []
  for r in ff.get_messages("record"): #r is record
    for d in r:
      # d is data field
      dataname = d.name
      datavalue = d.value
      unit = d.units
      if dataname in tablecontent:
        tablecontent[dataname].append(datavalue)
      else:
        tablecontent[dataname] = [datavalue]
        units.append(unit)
  dum = pd.DataFrame.from_dict(tablecontent, orient='index',).transpose()
  dum["id"] = n
  df0 = pd.concat([df0, dum], ignore_index=True)
df0.to_csv("/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/raw_rides.csv",index=False)
#save the units
U = [{"Feature": feature, "Units": unit}
     for feature, unit in zip(tablecontent.keys(), units)]

# Create a DataFrame from the list of dictionaries
unitdf = pd.DataFrame(U)
unitdf.to_excel("/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/units.xlsx",index=False)

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/raw_rides.csv") #just to save some time

#to convert to semicircles to coordinates
#Since all the rides are from North-East semisphere I won't check the signs.
def loc_converter(semi_lat,semi_lon):
  lat = (semi_lat / 2**31) * 180
  lon = (semi_lon/2**31)*180
  return lat, lon

#do not convert altitude
#do not convert cadence
df["distance"] = df["distance"]/1000 # meters to kilometers
#do not convert heart_rate
new_location = loc_converter(df["position_lat"],df["position_long"])
df["position_lat"] = new_location[0]
df["position_long"] = new_location[1]
df["speed"] = df["speed"]* 3.6 # m/s to km/h
df.drop(["enhanced_altitude","enhanced_speed","power","fractional_cadence","unknown_66","unknown_61","unknown_108"],axis=1,inplace= True)

missing = pd.DataFrame()
for i in df["id"].unique():
  subset = df[df["id"]==i][df.columns[:-1]]
  miss_rat = (subset.isna().mean()*100).round(3).to_dict()
  dum1 = pd.DataFrame.from_dict(miss_rat,orient='index').transpose()
  dum1["id"] = i
  dum1["time"] = (subset["timestamp"].iloc[0])[:10] #.astype(int)
  missing = pd.concat([dum1,missing],ignore_index=True)
missing = missing.iloc[::-1].reset_index(drop=True)
#Now if any feature missing more than 15% of the each ride, I will those rides as `unusable` and other will be labelled as `usable`.
threshold = 15
missing['Usage'] = missing[missing.columns[:8]].apply(lambda row: 1 if all(row <= threshold) else 0, axis=1)

usage_mapping = missing.set_index('id')['Usage'].to_dict()
df["Usage"] = df["id"].map(usage_mapping)
df.to_csv("/content/drive/MyDrive/Colab Notebooks/Cycling-adventures/data/output_data/convertedrides.csv",index=False)
missing.to_csv("/content/drive/MyDrive/Colab Notebooks/Cycyling data outputs/missing_values.csv",index=False)

missing[missing["Usage"]==1]